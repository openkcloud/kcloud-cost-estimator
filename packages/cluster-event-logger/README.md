# Logger Module - Scheduling Decision Tracking & Event Logging

**ìŠ¤ì¼€ì¤„ë§ ê²°ì • ê³¼ì • ì¶”ì  ë° ìµœì í™” ì´ë²¤íŠ¸ ë¡œê¹… ëª¨ë“ˆ**

## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥

### ğŸ“Š ìŠ¤ì¼€ì¤„ë§ ê²°ì • ê³¼ì • ë¡œê¹…
- **ì˜ì‚¬ê²°ì • ì¶”ì **: ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë‚´ë¦° ëª¨ë“  ê²°ì • ê³¼ì • ê¸°ë¡
- **ë¹„ìš© ê³„ì‚° ë¡œê·¸**: ì „ë ¥ ê¸°ë°˜ ë¹„ìš© ê³„ì‚° ê³¼ì • ìƒì„¸ ê¸°ë¡
- **ì›Œí¬ë¡œë“œ ë°°ì¹˜**: ì–´ë–¤ ì›Œí¬ë¡œë“œê°€ ì™œ íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì— ë°°ì¹˜ë˜ì—ˆëŠ”ì§€ ì¶”ì 
- **ì„±ëŠ¥ ë©”íŠ¸ë¦­**: ìŠ¤ì¼€ì¤„ë§ ì§€ì—°ì‹œê°„, ì²˜ë¦¬ëŸ‰ ë“± KPI ì¸¡ì •

### ğŸ”„ ìµœì í™” ì´ë²¤íŠ¸ ì¶”ì   
- **ì¬ë°°ì¹˜ ì´ë²¤íŠ¸**: ì›Œí¬ë¡œë“œ ì¬ë°°ì¹˜ ì‹œì , ì´ìœ , ê²°ê³¼ ê¸°ë¡
- **í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„±**: Magnum í´ëŸ¬ìŠ¤í„° ìƒì„±/ì‚­ì œ/ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸
- **ì •ì±… ë³€ê²½**: ìš´ìš© ì •ì±… ì ìš© ë° ë³€ê²½ ì´ë ¥
- **ë¹„íš¨ìœ¨ ê°ì§€**: ìì› ì‚¬ìš© ë¹„íš¨ìœ¨ ìƒíƒœ ê°ì§€ ë° ì•ŒëŒ

### ğŸ“ˆ ê°ì‚¬ ë° ë¶„ì„
- **ìš´ìš© ë¹„ìš© ë³€í™”**: ì •ì±… ì „í™˜ ì „í›„ ë¹„ìš© ë³€í™” ì¶”ì 
- **íš¨ìœ¨ì„± ë¶„ì„**: ìµœì í™” íš¨ê³¼ ì¸¡ì • ë° ë³´ê³ ì„œ ìƒì„±
- **SLA ì¤€ìˆ˜**: ì‘ë‹µì‹œê°„, ê°€ìš©ì„± ë“± SLA ì§€í‘œ ëª¨ë‹ˆí„°ë§
- **ê·œì • ì¤€ìˆ˜**: ê°ì‚¬ ë¡œê·¸ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ë³´ê³ ì„œ

## ğŸ— ì•„í‚¤í…ì²˜

```
ëª¨ë“  kcloud ëª¨ë“ˆ â†’ logger â†’ êµ¬ì¡°í™”ëœ ë¡œê·¸ â†’ ë¶„ì„/ëŒ€ì‹œë³´ë“œ
    â†“                â†“           â†“              â†“
ìŠ¤ì¼€ì¤„ë§ ì´ë²¤íŠ¸   ì´ë²¤íŠ¸ ì¶”ì    InfluxDB     Grafana ëŒ€ì‹œë³´ë“œ
ì¬ë°°ì¹˜ ê²°ì •      ë¡œê·¸ ì²˜ë¦¬     PostgreSQL   ê°ì‚¬ ë³´ê³ ì„œ
ë¹„ìš© ê³„ì‚°        ê°ì‚¬ ê´€ë¦¬     Elasticsearch ì•ŒëŒ ì‹œìŠ¤í…œ
```

## ğŸ¯ ì¶”ì  ëŒ€ìƒ ì´ë²¤íŠ¸

### **1. ìŠ¤ì¼€ì¤„ë§ ì´ë²¤íŠ¸**
```json
{
  "event_type": "scheduling_decision",
  "timestamp": "2025-01-15T10:30:00Z",
  "scheduler": "kcloud-meta-scheduler",
  "workload": {
    "id": "ml-training-job-123",
    "type": "ml_training",
    "requirements": {
      "cpu": 8,
      "memory": "32Gi", 
      "gpu": 2,
      "power_budget": 1500
    }
  },
  "decision": {
    "selected_cluster": "gpu-cluster-01",
    "reason": "ìµœì  ì „ë ¥ íš¨ìœ¨ì„±",
    "cost_calculation": {
      "estimated_power_watts": 1200,
      "estimated_cost_per_hour": 15.60,
      "alternatives": [
        {"cluster": "gpu-cluster-02", "cost": 18.20},
        {"cluster": "hybrid-cluster-01", "cost": 22.40}
      ]
    }
  },
  "execution_time_ms": 245
}
```

### **2. ì¬ë°°ì¹˜ ì´ë²¤íŠ¸**
```json
{
  "event_type": "workload_relocation",
  "timestamp": "2025-01-15T14:45:00Z",
  "trigger": "power_efficiency_optimization",
  "workload": "inference-service-456",
  "migration": {
    "from_cluster": "gpu-cluster-02",
    "to_cluster": "npu-cluster-01",
    "reason": "NPUê°€ ì¶”ë¡  ì‘ì—…ì— ë” íš¨ìœ¨ì ",
    "power_saving_watts": 300,
    "cost_saving_per_hour": 4.20
  },
  "migration_time_seconds": 45,
  "downtime_seconds": 2
}
```

### **3. í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„± ì´ë²¤íŠ¸**
```json
{
  "event_type": "cluster_reconfiguration",
  "timestamp": "2025-01-15T16:00:00Z",
  "action": "cluster_created",
  "cluster": {
    "id": "magnum-cluster-789",
    "name": "npu-inference-cluster",
    "type": "npu_optimized",
    "node_count": 3,
    "estimated_cost_per_hour": 12.50
  },
  "trigger": {
    "workload_queue_length": 15,
    "existing_cluster_utilization": 95,
    "expected_efficiency_gain": "25%"
  }
}
```

### **4. ë¹„íš¨ìœ¨ ê°ì§€ ì´ë²¤íŠ¸**
```json
{
  "event_type": "inefficiency_detected",
  "timestamp": "2025-01-15T18:20:00Z",
  "severity": "medium",
  "inefficiency": {
    "type": "idle_cluster",
    "cluster": "cpu-cluster-03",
    "utilization": 8,
    "idle_duration_hours": 6,
    "wasted_cost_estimate": 75.60
  },
  "recommended_action": "cluster_consolidation",
  "auto_action_taken": false
}
```

## ğŸ”§ ë¡œê·¸ ìˆ˜ì§‘ ë°©ë²•

### **êµ¬ì¡°í™”ëœ ë¡œê¹…**
- **JSON í˜•ì‹**: ëª¨ë“  ë¡œê·¸ë¥¼ JSONìœ¼ë¡œ êµ¬ì¡°í™”
- **í‘œì¤€í™”ëœ ìŠ¤í‚¤ë§ˆ**: ì´ë²¤íŠ¸ íƒ€ì…ë³„ ì¼ê´€ëœ ìŠ¤í‚¤ë§ˆ
- **ë©”íƒ€ë°ì´í„° íƒœê¹…**: ê²€ìƒ‰ ë° ë¶„ì„ì„ ìœ„í•œ íƒœê·¸ ìë™ ì¶”ê°€

### **ë‹¤ì–‘í•œ ìˆ˜ì§‘ ë°©ë²•**
```python
# 1. ì§ì ‘ API í˜¸ì¶œ
logger_client.log_scheduling_decision(
    workload_id="ml-job-123",
    cluster_id="gpu-cluster-01", 
    cost_calculation=cost_data,
    execution_time=245
)

# 2. ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° (Redis/Kafka)
event_publisher.publish("scheduling_events", event_data)

# 3. HTTP ì›¹í›…
requests.post("http://logger:8007/events/scheduling", json=event_data)

# 4. íŒŒì¼ ê¸°ë°˜ ë¡œê·¸ ìˆ˜ì§‘ (Fluent Bit/Filebeat)
# í‘œì¤€ ë¡œê·¸ íŒŒì¼ì„ loggerê°€ ìˆ˜ì§‘
```

## ğŸ“Š API ì—”ë“œí¬ì¸íŠ¸

```bash
# ì´ë²¤íŠ¸ ë¡œê¹…
POST /events/scheduling          # ìŠ¤ì¼€ì¤„ë§ ê²°ì • ë¡œê·¸
POST /events/relocation         # ì¬ë°°ì¹˜ ì´ë²¤íŠ¸ ë¡œê·¸  
POST /events/cluster            # í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„± ë¡œê·¸
POST /events/inefficiency       # ë¹„íš¨ìœ¨ì„± ê°ì§€ ë¡œê·¸

# ì´ë²¤íŠ¸ ì¡°íšŒ
GET /events                     # ì „ì²´ ì´ë²¤íŠ¸ ëª©ë¡
GET /events/{event_type}        # íƒ€ì…ë³„ ì´ë²¤íŠ¸ ì¡°íšŒ
GET /events/workload/{workload_id} # ì›Œí¬ë¡œë“œë³„ ì´ë²¤íŠ¸ ì¶”ì 

# ë¶„ì„ ë° ë³´ê³ ì„œ
GET /analytics/scheduling-performance  # ìŠ¤ì¼€ì¤„ë§ ì„±ëŠ¥ ë¶„ì„
GET /analytics/cost-efficiency         # ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„  
GET /analytics/sla-compliance          # SLA ì¤€ìˆ˜ í˜„í™©
GET /reports/audit                     # ê°ì‚¬ ë³´ê³ ì„œ ìƒì„±

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
GET /stream/events               # ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° (SSE)
GET /alerts/active               # í™œì„± ì•ŒëŒ ëª©ë¡
POST /alerts/rules               # ì•ŒëŒ ê·œì¹™ ì„¤ì •
```

## ğŸ§ª ì‚¬ìš© ì˜ˆì‹œ

### **ìŠ¤ì¼€ì¤„ë§ ê²°ì • ë¡œê¹…**
```python
from logger.event_tracker import EventTracker

tracker = EventTracker()

# ìŠ¤ì¼€ì¤„ë§ ê²°ì • ì‹œ
await tracker.log_scheduling_decision(
    workload_id="ml-training-job-456",
    selected_cluster="gpu-cluster-02",
    alternatives=[
        {"cluster": "gpu-cluster-01", "cost": 18.50},
        {"cluster": "hybrid-cluster", "cost": 22.30}
    ],
    cost_calculation={
        "power_watts": 1400,
        "cost_per_hour": 16.80,
        "efficiency_score": 0.85
    },
    execution_time_ms=180
)
```

### **ì¬ë°°ì¹˜ ì´ë²¤íŠ¸ ì¶”ì **
```python
# ì›Œí¬ë¡œë“œ ì¬ë°°ì¹˜ ì‹œ
await tracker.log_workload_relocation(
    workload_id="inference-service-789",
    from_cluster="gpu-cluster-01",
    to_cluster="npu-cluster-01", 
    trigger="power_optimization",
    metrics={
        "power_saving_watts": 250,
        "cost_saving_per_hour": 3.75,
        "migration_time_seconds": 35,
        "downtime_seconds": 1
    }
)
```

### **ë¹„íš¨ìœ¨ì„± ê°ì§€ ë° ì•ŒëŒ**
```python
# ë¹„íš¨ìœ¨ ìƒíƒœ ê°ì§€ ì‹œ
await tracker.log_inefficiency(
    inefficiency_type="idle_cluster",
    resource_id="cpu-cluster-05",
    severity="high",
    metrics={
        "utilization_percentage": 5,
        "idle_duration_hours": 12,
        "wasted_cost_estimate": 150.40
    },
    recommended_action="cluster_shutdown"
)
```

### **ë¶„ì„ ì¿¼ë¦¬**
```python
from logger.log_processor import LogAnalyzer

analyzer = LogAnalyzer()

# ìŠ¤ì¼€ì¤„ë§ ì„±ëŠ¥ ë¶„ì„
performance = await analyzer.analyze_scheduling_performance(
    time_range="7d",
    metrics=["avg_latency", "success_rate", "cost_efficiency"]
)

# ë¹„ìš© ì ˆê° íš¨ê³¼ ë¶„ì„
cost_analysis = await analyzer.analyze_cost_efficiency(
    time_range="30d",
    compare_baseline=True
)

print(f"í‰ê·  ìŠ¤ì¼€ì¤„ë§ ì§€ì—°ì‹œê°„: {performance['avg_latency_ms']}ms")
print(f"ì›”ê°„ ë¹„ìš© ì ˆê°ì•¡: ${cost_analysis['monthly_savings']}")
```

## ğŸš€ ë°°í¬

```bash
# ë¡œì»¬ ê°œë°œ
make install
make test
make run

# Docker ì‹¤í–‰
make docker-build
make docker-run

# K8s ë°°í¬  
kubectl apply -f deployment/logger.yaml

# ë¡œê·¸ ìˆ˜ì§‘ í™•ì¸
curl http://localhost:8007/health
curl http://localhost:8007/events?limit=10
```

## ğŸ“ˆ ì„±ëŠ¥ ëª©í‘œ

- **SFR.OPT.013**: ìŠ¤ì¼€ì¤„ë§ ê²°ì • ê³¼ì • ë¡œê·¸ ì €ì¥ ë° ì œê³µ âœ…
- **SFR.OPT.014**: ì¬ë°°ì¹˜/ì¬êµ¬ì„± ìµœì í™” ì´ë²¤íŠ¸ ì´ë ¥ ì œê³µ âœ…  
- **SNR.PF.010**: ìŠ¤ì¼€ì¤„ë§ ì§€ì—°ì‹œê°„ 30% ê°ì†Œ ëª¨ë‹ˆí„°ë§ âœ…
- **ë¡œê·¸ ì²˜ë¦¬ ì„±ëŠ¥**: ì´ˆë‹¹ 1000ê°œ ì´ë²¤íŠ¸ ì²˜ë¦¬ ê°€ëŠ¥
- **ì¿¼ë¦¬ ì‘ë‹µì‹œê°„**: ë³µì¡í•œ ë¶„ì„ ì¿¼ë¦¬ë„ 5ì´ˆ ì´ë‚´ ì‘ë‹µ